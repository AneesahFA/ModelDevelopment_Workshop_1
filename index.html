<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Portfolio Artifacts – Machine Learning & Neural Networks</title>
  <meta name="description" content="Artifact 1: ML Algorithms Visual Framework. Artifact 2: Neural Network Components & Architecture (Playground exploration)." />
  <style>
    :root{
      --ink:#e8eaf0; --muted:#aeb6c8; --accent:#7dd3fc;
      --super:#22c55e; --unsuper:#f59e0b; --deep:#a78bfa; --gen:#fb7185;
      --rule:rgba(255,255,255,.08); --wrap:1100px;
    }
    *{box-sizing:border-box}
    html{scroll-behavior:smooth}
    body{
      margin:0; color:var(--ink);
      font:16px/1.6 ui-sans-serif,system-ui,-apple-system,Segoe UI,Inter,Roboto,Arial;
      background:
        linear-gradient(180deg, rgba(10,12,18,.86), rgba(10,12,18,.86)),
        url('/assets/ml-bg.jpg') center/cover fixed no-repeat;
    }
    .wrap{max-width:var(--wrap); margin:auto; padding:28px 22px}
    header{margin:8px 0 18px}
    h1{margin:0 0 6px; font-size:clamp(26px,4vw,40px)}
    p.lead{margin:0; color:var(--muted)}
    .legend{display:flex; flex-wrap:wrap; gap:10px; margin:14px 0 4px}
    .chip{display:inline-flex; align-items:center; gap:8px; padding:6px 10px;
          border:1px solid var(--rule); border-radius:999px; background:rgba(17,19,27,.45);
          color:#d5dcec; font-size:12px}
    .dot{width:10px; height:10px; border-radius:50%}
    .super{color:var(--super)} .unsuper{color:var(--unsuper)}
    .deep{color:var(--deep)} .gen{color:var(--gen)}
    .dot.super{background:var(--super)} .dot.unsuper{background:var(--unsuper)}
    .dot.deep{background:var(--deep)} .dot.gen{background:var(--gen)}
    .hero{margin:14px 0 20px}
    .hero img{width:100%; border-radius:12px; border:1px solid var(--rule)}
    .hr{height:1px; background:var(--rule); margin:22px 0}
    section{padding:10px 0}
    h2{margin:0 0 4px; font-size:22px}
    h3{margin:18px 0 8px; font-size:19px}
    .kicker{margin:0 0 12px; color:var(--muted)}
    dl{display:grid; grid-template-columns: 180px 1fr; gap:6px 16px; margin:0}
    dt{color:#c9d2e6; opacity:.9}
    dd{margin:0}
    ul{margin:6px 0 0 18px}
    footer{color:var(--muted); margin:26px 0 10px; font-size:14px}

    /* top nav */
    .topnav{
      position:sticky; top:0; z-index:10;
      backdrop-filter:saturate(140%) blur(8px);
      background:rgba(15,18,26,.65); border-bottom:1px solid var(--rule);
    }
    .topnav .inner{max-width:var(--wrap); margin:auto; padding:10px 22px; display:flex; gap:10px}
    .tab{
      color:#e7edf9; text-decoration:none; padding:8px 12px; border:1px solid var(--rule);
      border-radius:10px; background:rgba(255,255,255,.05); font-weight:600
    }
    .tab:hover{background:rgba(255,255,255,.09)}
    .badge{font-size:12px; opacity:.85; margin-left:6px; padding:2px 6px; border-radius:999px; background:rgba(125,211,252,.15); border:1px solid var(--rule)}
    .callout{background:rgba(255,255,255,.05); border:1px solid var(--rule); border-radius:12px; padding:14px}
    .two-col{display:grid; grid-template-columns: 1fr; gap:14px}
    @media (min-width:900px){ .two-col{grid-template-columns: 1.1fr .9fr} }
    .img-frame{border:1px solid var(--rule); border-radius:12px; overflow:hidden}
    .img-frame img{width:100%; display:block}
    .small{color:var(--muted); font-size:14px}
  </style>
</head>
<body>
  <!-- Sticky top navigation: jump between artifacts -->
  <nav class="topnav">
    <div class="inner">
      <a class="tab" href="#artifact-1">Artifact 1 <span class="badge">ML Algorithms</span></a>
      <a class="tab" href="#artifact-2">Artifact 2 <span class="badge">Neural Networks</span></a>
    </div>
  </nav>

  <div class="wrap">

    <!-- =============== ARTIFACT 1 =============== -->
    <section id="artifact-1">
      <header>
        <h1>Artifact 1 — Machine Learning Algorithms: Visual Framework</h1>
        <p class="lead">Each algorithm includes: <em>Algorithm Type</em>, <em>Application Domains</em>, <em>Example Applications</em>, and a <em>Brief Explanation</em>.</p>
        <div class="legend">
          <span class="chip"><span class="dot super"></span> Supervised</span>
          <span class="chip"><span class="dot unsuper"></span> Unsupervised</span>
          <span class="chip"><span class="dot deep"></span> Deep Learning</span>
          <span class="chip"><span class="dot gen"></span> Generative AI</span>
        </div>
      </header>

      <div class="hero">
        <img src="assets/machine.jpg" alt="Infographic banner: ML algorithms">
      </div>

      <div class="hr"></div>

      <!-- *** Your original 10-algorithm sections remain unchanged below *** -->

      <!-- 1 Decision Tree -->
      <section class="alg" id="decision-tree">
        <h2>Decision Tree <span class="super">• Supervised</span></h2>
        <p class="kicker">If/then splits create a readable tree of decisions.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Supervised (Classification/Regression)</dd>
          <dt>Application Domains</dt><dd>Tabular Data, Explainable AI</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Credit approval</li>
              <li>Customer churn prediction</li>
              <li>Clinical triage rules</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Recursively splits features at thresholds that best separate labels; leaves are final predictions.</dd>
        </dl>
        <img src="assets/1.jpg" alt="Decision Tree Infographic">
      </section>

      <div class="hr"></div>

      <!-- 2 Random Forest -->
      <section class="alg" id="random-forest">
        <h2>Random Forest <span class="super">• Supervised</span></h2>
        <p class="kicker">Ensemble of trees that vote, robust and strong baseline.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Supervised (Classification/Regression)</dd>
          <dt>Application Domains</dt><dd>Tabular Data, Feature Importance</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Risk scoring & fraud detection</li>
              <li>Price prediction</li>
              <li>Variable importance ranking</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Trains many trees on bootstrapped samples with random feature subsets; aggregates their predictions to reduce overfitting.</dd>
        </dl>
        <img src="assets/2.jpg" alt="Random Forest Infographic">
      </section>

      <div class="hr"></div>

      <!-- 3 SVM -->
      <section class="alg" id="svm">
        <h2>Support Vector Machine (SVM) <span class="super">• Supervised</span></h2>
        <p class="kicker">Finds the maximum-margin decision boundary.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Supervised (Classification; One-Class for anomaly)</dd>
          <dt>Application Domains</dt><dd>Tabular, NLP (linear), Vision (HOG+SVM)</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Text/topic classification</li>
              <li>Image category recognition</li>
              <li>Anomaly detection</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Uses kernels to separate classes with the widest margin; support vectors define the boundary (hyperplane).</dd>
        </dl>
        <img src="assets/3.jpg" alt="SVM Infographic">
      </section>

      <div class="hr"></div>

      <!-- 4 Logistic Regression -->
      <section class="alg" id="logistic-regression">
        <h2>Logistic Regression <span class="super">• Supervised</span></h2>
        <p class="kicker">Simple, interpretable probabilities for yes/no outcomes.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Supervised (Binary/Multiclass Classification)</dd>
          <dt>Application Domains</dt><dd>Tabular Data, Classic NLP (bag-of-words)</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Spam vs ham email filtering</li>
              <li>Lead conversion likelihood</li>
              <li>Ad click-through prediction</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Linear model with a sigmoid link maps features to class probabilities; coefficients show feature influence.</dd>
        </dl>
        <img src="assets/4.jpg" alt="Logistic Regression Infographic">
      </section>

      <div class="hr"></div>

      <!-- 5 K-Means -->
      <section class="alg" id="kmeans">
        <h2>K-Means Clustering <span class="unsuper">• Unsupervised</span></h2>
        <p class="kicker">Groups points by nearest centroid; fast and scalable.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Unsupervised (Clustering)</dd>
          <dt>Application Domains</dt><dd>Tabular, Vision (color clusters), Marketing</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Customer segmentation</li>
              <li>Image color quantization</li>
              <li>Document/topic grouping</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Iteratively assigns points to the closest centroid and updates centroids to the mean until assignments stabilize.</dd>
        </dl>
        <img src="assets/5.jpg" alt="K-Means Clustering Infographic">
      </section>

      <div class="hr"></div>

      <!-- 6 PCA -->
      <section class="alg" id="pca">
        <h2>Principal Component Analysis (PCA) <span class="unsuper">• Unsupervised</span></h2>
        <p class="kicker">Dimensionality reduction while preserving variance.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Unsupervised (Projection/Compression)</dd>
          <dt>Application Domains</dt><dd>Preprocessing, Visualization, Noise Reduction</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Feature compression for ML pipelines</li>
              <li>2D/3D plots of high-dimensional data</li>
              <li>SNR improvement in sensor data</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Computes orthogonal components (eigenvectors) ordered by explained variance; projects data onto top components.</dd>
        </dl>
        <img src="assets/6.jpg" alt="PCA Infographic">
      </section>

      <div class="hr"></div>

      <!-- 7 CNN -->
      <section class="alg" id="cnn">
        <h2>Convolutional Neural Network (CNN) <span class="deep">• Deep Learning</span></h2>
        <p class="kicker">Spatial feature extractor for images and video.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Deep Learning (Supervised)</dd>
          <dt>Application Domains</dt><dd>Computer Vision, Medical Imaging, Remote Sensing</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Image classification & object detection</li>
              <li>Tumor/lesion screening</li>
              <li>Quality inspection on production lines</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Stacks convolutions and pooling to capture local edges/textures that compose higher-level visual features.</dd>
        </dl>
        <img src="assets/7.jpg" alt="Convolutional Neural Network Infographic">
      </section>

      <div class="hr"></div>

      <!-- 8 RNN/LSTM -->
      <section class="alg" id="lstm">
        <h2>RNN / LSTM <span class="deep">• Deep Learning</span></h2>
        <p class="kicker">Models sequences with memory over time.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Deep Learning (Supervised)</dd>
          <dt>Application Domains</dt><dd>NLP, Speech, Time Series</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Language modeling & next-word prediction</li>
              <li>Demand/energy forecasting</li>
              <li>Speech recognition</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Recurrent connections pass hidden state between steps; LSTM gates regulate what to keep, write, or forget.</dd>
        </dl>
        <img src="assets/8.jpg" alt="RNN LSTM Infographic">
      </section>

      <div class="hr"></div>

      <!-- 9 GANs -->
      <section class="alg" id="gans">
        <h2>Generative Adversarial Networks (GANs) <span class="gen">• Generative AI</span></h2>
        <p class="kicker">Two networks compete: generator vs. discriminator.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Generative (Unsupervised/Self-supervised)</dd>
          <dt>Application Domains</dt><dd>Computer Vision, Synthetic Data, Creative Tools</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Image synthesis & style transfer</li>
              <li>Privacy-preserving data augmentation</li>
              <li>Restoration (super-resolution, de-noise)</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>A generator creates samples; a discriminator judges real vs fake. Adversarial training improves sample realism.</dd>
        </dl>
        <img src="assets/9.jpg" alt="GANs Infographic">
      </section>

      <div class="hr"></div>

      <!-- 10 Transformers -->
      <section class="alg" id="transformers">
        <h2>Transformers (BERT / GPT) <span class="deep">• Deep Learning / NLP</span></h2>
        <p class="kicker">Self-attention captures long-range context in parallel.</p>
        <dl>
          <dt>Algorithm Type</dt><dd>Deep Learning (Encoder/Decoder; Pre-training + Fine-tuning)</dd>
          <dt>Application Domains</dt><dd>NLP, Multimodal (text-image-audio), Code</dd>
          <dt>Example Applications</dt>
          <dd>
            <ul>
              <li>Translation, Q&A, summarization</li>
              <li>Text & code generation</li>
              <li>Search/ranking with embeddings</li>
            </ul>
          </dd>
          <dt>Brief Explanation</dt>
          <dd>Attention weights relate every token to every other; positional encodings add order. Enables scalable parallel training.</dd>
        </dl>
        <img src="assets/10.jpg" alt="Transformers Infographic">
      </section>

      <footer>
        <p>© <span id="yr"></span> Aneesah • GitHub Pages Portfolio Artifact</p>
      </footer>
      <div class="hr"></div>
    </section>

  <!-- =============== ARTIFACT 2 =============== -->
<section id="artifact-2">
  <header>
    <h1>Artifact 2 — Neural Network Components & Architecture</h1>
    <p class="lead">This artifact explores the structure and function of artificial neural networks using the <em>Neural Network Playground</em>. It demonstrates how key components—layers, neurons, weights, activations, loss functions, and optimizers—interact to enable learning and pattern recognition.</p>
  </header>

  <div class="hero">
    <img src="assets/NNArchitecture.png" alt="Feedforward Neural Network Architecture Diagram">
  </div>

  <h3>Define and Describe Components</h3>
  <div class="callout">
    <h4>1. Layers</h4>
    <p>
      Neural networks are organized into layers that process data in stages.  
      The <strong>Input Layer</strong> receives raw data (features), passing it forward to one or more <strong>Hidden Layers</strong> that extract patterns and relationships through weighted transformations.  
      Finally, the <strong>Output Layer</strong> produces predictions or classifications based on the learned representations.  
      Each layer increases the network’s ability to model complex, nonlinear relationships.
    </p>

    <h4>2. Neurons</h4>
    <p>
      A neuron, also known as a node or unit, is the core computational element of a neural network.  
      Each neuron receives input values, multiplies them by corresponding weights, adds a bias, and applies an activation function.  
      The result is passed to the next layer.  
      This simple operation, when repeated across thousands of neurons and layers, allows networks to perform tasks such as image recognition, language understanding, and prediction.
    </p>

    <h4>3. Weights</h4>
    <p>
      <strong>Weights</strong> determine how strongly each input feature or neuron influences the next layer.  
      They are the network’s learnable parameters and are adjusted during training to minimize prediction error.  
      High positive weights strengthen a connection, while negative or smaller weights reduce its impact.  
      Collectively, weights define what the network has “learned” from the data.
    </p>

    <h4>4. Activation Functions</h4>
    <p>
      Activation functions introduce <strong>non-linearity</strong> into the model, enabling it to learn complex, nonlinear patterns.  
      Without activations, the entire network would behave like a simple linear regression.  
      Common activation functions include:
      <ul>
        <li><strong>ReLU (Rectified Linear Unit):</strong> Efficient and widely used; outputs 0 for negative inputs and linear for positives.</li>
        <li><strong>Sigmoid:</strong> Maps values between 0 and 1, often used for probabilities.</li>
        <li><strong>Tanh:</strong> Similar to sigmoid but ranges from -1 to 1, allowing negative activations.</li>
      </ul>
    </p>

    <h4>5. Loss Functions</h4>
    <p>
      The <strong>Loss Function</strong> measures how far the model’s predictions are from the true outputs.  
      It provides numerical feedback to guide learning—lower loss means better performance.  
      In this network, we use the <strong>Mean Squared Error (MSE)</strong>, which calculates the average of the squared differences between predicted and actual values.  
      This function is ideal for regression tasks and helps the optimizer minimize overall prediction error during training.
    </p>

    <h4>6. Optimization Algorithms</h4>
    <p>
      Optimization algorithms adjust the network’s weights to reduce the loss function.  
      They calculate gradients using <strong>backpropagation</strong> and update weights in the direction that lowers error.  
      Common optimizers include:
      <ul>
        <li><strong>Stochastic Gradient Descent (SGD):</strong> Updates weights incrementally for faster convergence.</li>
        <li><strong>Adam Optimizer:</strong> Combines the benefits of momentum and adaptive learning rates, improving stability and speed.</li>
      </ul>
      The optimizer is crucial because it ensures that learning happens efficiently and avoids getting stuck in local minima.
    </p>
  </div>

  <h3>Summary</h3>
  <p class="callout">
    This visualization demonstrates how each component contributes to the neural network’s learning process.  
    Layers structure the flow of information, neurons perform the core computations, and weights capture learned relationships.  
    Activation functions enable flexibility and non-linearity, while the loss function measures performance and drives improvement.  
    Finally, the optimizer refines the model by adjusting weights over many iterations.  
    Through experiments in the Neural Network Playground, it becomes clear that even small changes in architecture—like increasing neurons or altering activations—can significantly impact how well a model learns and generalizes.
  </p>
</section>

  </div>
  <script>document.getElementById('yr').textContent=new Date().getFullYear()</script>
</body>
</html>
